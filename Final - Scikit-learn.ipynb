{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Scikit-learn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets create our Sagemaker session and role, and create a S3 prefix to use for the notebook example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from datetime import datetime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "smclient = sagemaker_session.sagemaker_client\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training <a class=\"anchor\" id=\"upload_data\"></a>\n",
    "\n",
    "For the purposes of this example, we're using a sample of the classic Iris dataset, which is included with Scikit-learn. We will load the dataset, write locally, then write the dataset to s3 to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris dataset, then join labels and features\n",
    "iris = datasets.load_iris()\n",
    "joined_iris = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "\n",
    "# Create directory and write csv\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "np.savetxt('./data/iris.csv', joined_iris, delimiter=',', fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data locally, we can use use the tools provided by the SageMaker Python SDK to upload the data to a default bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'Scikit-iris'\n",
    "folder = 'data'\n",
    "\n",
    "train_input = sagemaker_session.upload_data(folder, key_prefix=f\"{bucket}/{folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Scikit-learn script to train <a class=\"anchor\" id=\"create_sklearn_script\"></a>\n",
    "SageMaker can now run a scikit-learn script using the `SKLearn` estimator. When executed on SageMaker a number of helpful environment variables are available to access properties of the training environment, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to. Any artifacts saved in this folder are uploaded to S3 for model hosting after the training job completes.\n",
    "* `SM_OUTPUT_DIR`: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing two input channels, 'train' and 'test', were used in the call to the `SKLearn` estimator's `fit()` method, the following environment variables will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAIN`: A string representing the path to the directory containing data in the 'train' channel\n",
    "* `SM_CHANNEL_TEST`: Same as above, but for the 'test' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance. \n",
    "\n",
    "Because the Scikit-learn container imports your training script, you should always put your training code in a main guard `(if __name__=='__main__':)` so that the container does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For more information about training environment variables, please visit https://github.com/aws/sagemaker-containers.\n",
    "\n",
    "For example, the script that we will run in this notebook is the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_train.py\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.externals import joblib\n",
    "  \n",
    "\n",
    "def load_preprocess():\n",
    "    \"\"\"\n",
    "        Take the set of files and read them all into a single pandas dataframe\n",
    "    \"\"\"\n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train) ]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "    raw_data = [ pd.read_csv(file, header=None, engine=\"python\") for file in input_files ]\n",
    "    train_data = pd.concat(raw_data)\n",
    "\n",
    "    # labels are in the first column\n",
    "    train_y = train_data.ix[:,0]\n",
    "    train_X = train_data.ix[:,1:]\n",
    "    \n",
    "    return train_X, train_y\n",
    "\n",
    "\n",
    "def train(train_X, train_y):\n",
    "    \"\"\"\n",
    "        Now use scikit-learn's decision tree classifier to train the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier = tree.DecisionTreeClassifier(max_leaf_nodes = args.max_leaf_nodes,\n",
    "                                             min_samples_leaf = args.min_samples_leaf)\n",
    "    classifier = classifier.fit(train_X, train_y)\n",
    "    \n",
    "    return classifier\n",
    "    \n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "        Load you model fron the S3 bucket and returns it. This function must be\n",
    "        must provide in your script.\n",
    "    \"\"\"\n",
    "    classifier = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return classifier\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here. In this simple example we are just including one hyperparameter.\n",
    "    parser.add_argument('--max_leaf_nodes', type=int, default=30)\n",
    "    parser.add_argument('--min_samples_leaf', type=int, default=1)\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Preprocess the data\n",
    "    train_X, train_y = load_preprocess()\n",
    "    \n",
    "    # Train our classifier\n",
    "    classifier = train(train_X, train_y)\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(classifier, os.path.join(args.model_dir, \"model.joblib\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the script above we have dfine the function `model_fn`, which load our model. After our model had been loaded we have to serve it. Model serving is the process in which the model response to inference request. This process is divided into 3 steps(functions):\n",
    "\n",
    "* `input_fn`\n",
    "* `predict_fn`\n",
    "* `output_fn`\n",
    "\n",
    "Each step involves invoking a python function, with information about the request and the return-value from the previous function in the chain. Inside the SageMaker Scikit-learn model server, the process looks like:\n",
    "\n",
    "```python\n",
    "# Deserialize the Invoke request body into an object we can perform prediction on\n",
    "input_object = input_fn(request_body, request_content_type)\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "prediction = predict_fn(input_object, model)\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "output = output_fn(prediction, response_content_type)\n",
    "```\n",
    "\n",
    "SageMaker Scikit-learn model server provide default implementations for the 3 functions. But we can override them if we need it.\n",
    "\n",
    "Default funtions, see https://github.com/aws/sagemaker-scikit-learn-container/blob/master/src/sagemaker_sklearn_container/serving.py\n",
    "\n",
    "More info at https://sagemaker.readthedocs.io/en/stable/using_sklearn.html#process-input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Scikit Estimator  <a class=\"anchor\" id=\"create_sklearn_estimator\"></a>\n",
    "\n",
    "To run our Scikit-learn training script on SageMaker we need a `sagemaker.sklearn.estimator.sklearn` estimator. We can construct a new estimator (model) or use a previous one we already had created. Our sklearn estimator accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training. __Note__: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker.\n",
    "* __hyperparameters__ *(optional)*: A dictionary passed to the train function as hyperparameters. \n",
    "\n",
    "To see the code for the SKLearn Estimator, see here: https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new estimator (model) must especify the entry point (our python script), the instance type, the role and the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'preprocess_train.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={'max_leaf_nodes': 30,\n",
    "                     'min_samples_leaf': 1})\n",
    "type(sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already have an existing pretrained model we can load our model (passing hyperparameter \"model-dir\") and then attach an existing training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-12 14:02:42 Starting - Preparing the instances for training\n",
      "2020-02-12 14:02:42 Downloading - Downloading input data\n",
      "2020-02-12 14:02:42 Training - Training image download completed. Training in progress.\n",
      "2020-02-12 14:02:42 Uploading - Uploading generated training model\n",
      "2020-02-12 14:02:42 Completed - Training job completed\u001b[34m2020-02-12 14:02:31,255 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:31,257 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:31,268 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:31,555 sagemaker-containers INFO     Module preprocess_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:31,555 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:31,555 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:31,555 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: preprocess-train\n",
      "  Building wheel for preprocess-train (setup.py): started\n",
      "  Building wheel for preprocess-train (setup.py): finished with status 'done'\n",
      "  Created wheel for preprocess-train: filename=preprocess_train-1.0.0-py2.py3-none-any.whl size=6573 sha256=010850848b3ab4766aadbf0be078a4bc3274412b87934c1f2abba9de37745d98\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tgs2h1os/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built preprocess-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: preprocess-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed preprocess-train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:33,001 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:33,013 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_leaf_nodes\": 30,\n",
      "        \"min_samples_leaf\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-02-12-14-00-09-401\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-788236952534/sagemaker-scikit-learn-2020-02-12-14-00-09-401/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"preprocess_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"preprocess_train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"max_leaf_nodes\":30,\"min_samples_leaf\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=preprocess_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=preprocess_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-788236952534/sagemaker-scikit-learn-2020-02-12-14-00-09-401/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max_leaf_nodes\":30,\"min_samples_leaf\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-02-12-14-00-09-401\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-788236952534/sagemaker-scikit-learn-2020-02-12-14-00-09-401/source/sourcedir.tar.gz\",\"module_name\":\"preprocess_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"preprocess_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--max_leaf_nodes\",\"30\",\"--min_samples_leaf\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEAF_NODES=30\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_SAMPLES_LEAF=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m preprocess_train --max_leaf_nodes 30 --min_samples_leaf 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocess_train.py:22: FutureWarning: \u001b[0m\n",
      "\u001b[34m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[34m.loc for label based indexing or\u001b[0m\n",
      "\u001b[34m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[34mSee the documentation here:\u001b[0m\n",
      "\u001b[34mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  train_y = train_data.ix[:,0]\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocess_train.py:23: FutureWarning: \u001b[0m\n",
      "\u001b[34m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[34m.loc for label based indexing or\u001b[0m\n",
      "\u001b[34m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[34mSee the documentation here:\u001b[0m\n",
      "\u001b[34mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  train_X = train_data.ix[:,1:]\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:822: FutureWarning: \u001b[0m\n",
      "\u001b[34m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[34m.loc for label based indexing or\u001b[0m\n",
      "\u001b[34m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[34mSee the documentation here:\u001b[0m\n",
      "\u001b[34mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\u001b[0m\n",
      "\u001b[34m2020-02-12 14:02:34,444 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 47\n",
      "Billable seconds: 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sagemaker.sklearn.estimator.SKLearn"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'preprocess_train.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={'max_leaf_nodes': 30,\n",
    "                     'min_samples_leaf': 1,\n",
    "                     \"model-dir\": \"s3://sagemaker-eu-west-1-788236952534/sagemaker-scikit-learn-2020-01-27-15-15-44-131/output/model.tar.gz\"})\n",
    "\n",
    "sklearn = sklearn.attach(training_job_name = \"sagemaker-scikit-learn-2020-02-12-14-00-09-401\")\n",
    "type(sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sklearn.image_name)\n",
    "# print(sklearn.hyperparameters())\n",
    "# print(sklearn.latest_job_debugger_artifacts_path)\n",
    "# print(sklearn.output_path)\n",
    "# print(sklearn.model_data)\n",
    "# print(sklearn.train_image())\n",
    "# print(sklearn.base_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As example, once we have our model stored in our S3 bucket we can download and rebuild it at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "# # use joblib from sklearn.externals, as in training script\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "# key_prefix = \"sagemaker-scikit-learn-2020-01-27-15-15-44-131/output/model.tar.gz\"\n",
    "# bucket = \"sagemaker-eu-west-1-788236952534\"\n",
    "# sagemaker_session.download_data(bucket = bucket, key_prefix = key_prefix, path=\"model\")\n",
    "\n",
    "# # decompress\n",
    "# tar = tarfile.open(\"model/model.tar.gz\", \"r:gz\")\n",
    "# tar.extractall(\"model/\")\n",
    "# tar.close()\n",
    "\n",
    "# # load model with joblib\n",
    "# model = joblib.load(\"model/model.joblib\")\n",
    "# type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SKLearn Estimator on Iris data <a class=\"anchor\" id=\"train_sklearn\"></a>\n",
    "Training is very simple, just call `fit` on the Estimator! This will start a SageMaker Training job that will download the data for us, invoke our scikit-learn code (in the provided script file), and save any model artifacts that the script creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning <a class=\"anchor\" id=\"train_sklearn\"></a>\n",
    "\n",
    "Now to configure the tuning job by defining a JSON object that you pass as the value of the TuningJobConfig parameter to the create_tuning_job call. In this JSON object, you specify:\n",
    "\n",
    "* The ranges of hyperparameters you want to tune\n",
    "* The limits of the resource the tuning job can consume\n",
    "* The objective metric for the tuning job\n",
    "\n",
    "See, https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "job_name = f\"scikitlearn-{now}\"\n",
    "\n",
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "      \"CategoricalParameterRanges\": [],\n",
    "      \"ContinuousParameterRanges\": [],\n",
    "      \"IntegerParameterRanges\": [{\n",
    "                \"MaxValue\": \"30\",\n",
    "                \"MinValue\": \"10\",\n",
    "                \"Name\": \"max_leaf_nodes\",\n",
    "                \"ScalingType\": \"Auto\"\n",
    "            },{\n",
    "                \"MaxValue\": \"5\",\n",
    "                \"MinValue\": \"1\",\n",
    "                \"Name\": \"min_samples_leaf\",\n",
    "                \"ScalingType\": \"Auto\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "        \"MaxNumberOfTrainingJobs\": 1,\n",
    "        \"MaxParallelTrainingJobs\": 3\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "        \"MetricName\": \"auc\",\n",
    "        \"Type\": \"Maximize\"\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure the training jobs the tuning job launches by defining a JSON object that you pass as the value of the TrainingJobDefinition parameter to the create_tuning_job call. In this JSON object, you specify:\n",
    "\n",
    "* Metrics that the training jobs emit\n",
    "* The container image for the algorithm to train\n",
    "* The input configuration for your training and test data\n",
    "* Configuration for the output of the algorithm\n",
    "* The values of any algorithm hyperparameters that are not tuned in the tuning job\n",
    "* The type of instance to use for the training jobs\n",
    "* The stopping condition for the training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = dict(sklearn.latest_training_job.describe()[\"InputDataConfig\"][0])\n",
    "train_input_path = train_input_path[\"DataSource\"][\"S3DataSource\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"MetricDefinitions\": [{\n",
    "            \"Name\": \"auc\",\n",
    "            \"Regex\": \"Auc = (.*?);\"\n",
    "        }],\n",
    "        \"TrainingImage\": f\"{sklearn.train_image()}\",\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"InputDataConfig\": [{\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"CompressionType\": \"None\",\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": train_input_path\n",
    "            }\n",
    "        }\n",
    "      },\n",
    "#       {\n",
    "#         \"ChannelName\": \"validation\",\n",
    "#         \"CompressionType\": \"None\",\n",
    "#         \"ContentType\": \"csv\",\n",
    "#         \"DataSource\": {\n",
    "#           \"S3DataSource\": {\n",
    "#             \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "#             \"S3DataType\": \"S3Prefix\",\n",
    "#             \"S3Uri\": s3_input_validation\n",
    "#           }\n",
    "#         }\n",
    "#       }\n",
    "    ],\n",
    "    \"OutputDataConfig\": { #Model artifacts\n",
    "        \"S3OutputPath\": f\"{sklearn.output_path}tunning\"\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.c4.xlarge\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"StoppingCondition\":{\n",
    "        \"MaxRuntimeInSeconds\": 1800\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobArn': 'arn:aws:sagemaker:eu-west-1:788236952534:hyper-parameter-tuning-job/scikitlearn-2020-02-13-08-25-45',\n",
       " 'ResponseMetadata': {'RequestId': '4ab8bdb7-1716-4fd2-88a6-f55f61864f14',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4ab8bdb7-1716-4fd2-88a6-f55f61864f14',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '132',\n",
       "   'date': 'Thu, 13 Feb 2020 08:26:09 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = job_name,\n",
    "                                           HyperParameterTuningJobConfig = tuning_job_config,\n",
    "                                           TrainingJobDefinition = training_job_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smclient.stop_hyper_parameter_tuning_job(HyperParameterTuningJobName=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InProgress'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'scikitlearn-2020-02-13-08-25-45',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:eu-west-1:788236952534:hyper-parameter-tuning-job/scikitlearn-2020-02-13-08-25-45',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Maximize',\n",
       "   'MetricName': 'auc'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 1,\n",
       "   'MaxParallelTrainingJobs': 3},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [{'Name': 'max_leaf_nodes',\n",
       "     'MinValue': '10',\n",
       "     'MaxValue': '30',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'min_samples_leaf',\n",
       "     'MinValue': '1',\n",
       "     'MaxValue': '5',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'ContinuousParameterRanges': [],\n",
       "   'CategoricalParameterRanges': []}},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'auc'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '141502667606.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'auc', 'Regex': 'Auc = (.*?);'},\n",
       "    {'Name': 'ObjectiveMetric', 'Regex': 'Auc = (.*?);'}]},\n",
       "  'RoleArn': 'arn:aws:iam::788236952534:role/service-role/AmazonSageMaker-ExecutionRole-20191202T102598',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-eu-west-1-788236952534/Scikit-iris/data',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'csv',\n",
       "    'CompressionType': 'None'}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-eu-west-1-788236952534/tunning'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.c4.xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 5},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 1800},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'InProgress',\n",
       " 'CreationTime': datetime.datetime(2020, 2, 13, 8, 26, 9, 964000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 2, 13, 8, 26, 17, 7000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 0,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 0, 'Pending': 0, 'Failed': 0},\n",
       " 'ResponseMetadata': {'RequestId': '26f04d1a-3f82-4d7f-9e22-0c09ef84341e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '26f04d1a-3f82-4d7f-9e22-0c09ef84341e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2032',\n",
       "   'date': 'Thu, 13 Feb 2020 08:26:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the trained model to make inference requests <a class=\"anchor\" id=\"inference\"></a>\n",
    "\n",
    "### Deploy the model. Create our endpoint <a class=\"anchor\" id=\"deploy\"></a>\n",
    "\n",
    "Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, \n",
    "                           instance_type=\"ml.t2.medium\", \n",
    "                           endpoint_name=\"scikitlearn-endpoint\")\n",
    "\n",
    "print(f\"\\n{type(predictor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already have an existing endpoint deployed we can create our predictor `sagemaker.sklearn.model.SKLearnPredictor` based on it simply filling the endpoint_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_loaded = sagemaker.sklearn.model.SKLearnPredictor(endpoint_name=\"scikitlearn-endpoint\", \n",
    "#                                                             sagemaker_session=sagemaker_session)\n",
    "\n",
    "# print(type(predictor_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s check the state of our recently endpoint deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.session.boto3.client(\"sagemaker\").describe_endpoint(EndpointName=predictor.endpoint)['EndpointName']\n",
    "status = sagemaker.session.boto3.client(\"sagemaker\").describe_endpoint(EndpointName=predictor.endpoint)['EndpointStatus']\n",
    "\n",
    "print(f\"End point: {endpoint_name} \\n\"\n",
    "      f\"Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some data and use it for a prediction <a class=\"anchor\" id=\"prediction_request\"></a>\n",
    "\n",
    "In order to do some predictions, we'll extract some of the data we used for training and do predictions against it. This is, of course, bad statistical practice, but a good way to see how the mechanism works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "shape = pd.read_csv(\"data/iris.csv\", header=None, engine=\"python\")\n",
    "\n",
    "a = [50*i for i in range(3)]\n",
    "b = [40+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "test_X = test_data.iloc[:,1:]\n",
    "test_y = test_data.iloc[:,0]\n",
    "type(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is as easy as calling predict with the predictor we got back from deploy and the data we want to do predictions with. The output from the endpoint return an numerical representation of the classification prediction; in the original dataset, these are flower names, but in this example the labels are numerical. We can compare against the original label that we parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(predictor.predict(test_X.values))\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint cleanup <a class=\"anchor\" id=\"endpoint_cleanup\"></a>\n",
    "\n",
    "When you're done with the endpoint, you'll want to clean it up.\n",
    "\n",
    "__¡¡¡ Beware of living the endpoint deployed if you are not gonna use it, it charge per hour deployed !!!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
